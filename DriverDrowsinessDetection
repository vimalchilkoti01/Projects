import cv2
import face_recognition
import numpy as np
from scipy.spatial import distance as dist
from playsound import playsound
from threading import Thread

# Function to calculate the Eye Aspect Ratio (EAR)
def eye_aspect_ratio(eye):
    A = dist.euclidean(eye[1], eye[5])
    B = dist.euclidean(eye[2], eye[4])
    C = dist.euclidean(eye[0], eye[3])
    ear = (A + B) / (2.0 * C)
    return ear

# Function to play sound in a separate thread
def play_sound(path):
    playsound(path)

# Function to send a message to the driver
def send_message(message):
    print(message)

# Thresholds
EYE_AR_THRESH = 0.25
EYE_AR_CONSEC_FRAMES = 20

# Initialize counters
COUNTER = 0

# Load the cascade for eye detection
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

# Start the video stream
cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # Detect faces
    face_locations = face_recognition.face_locations(rgb_frame)

    for (top, right, bottom, left) in face_locations:
        face_landmarks = face_recognition.face_landmarks(rgb_frame, [(top, right, bottom, left)])[0]

        leftEye = face_landmarks['left_eye']
        rightEye = face_landmarks['right_eye']

        leftEAR = eye_aspect_ratio(leftEye)
        rightEAR = eye_aspect_ratio(rightEye)

        ear = (leftEAR + rightEAR) / 2.0

        # Check if the eye aspect ratio is below the blink threshold
        if ear < EYE_AR_THRESH:
            COUNTER += 1
            if COUNTER >= EYE_AR_CONSEC_FRAMES:
                t = Thread(target=play_sound, args=('alarm.wav',))
                t.deamon = True
                t.start()
                send_message("Eyes closed! Wake up!")
        else:
            COUNTER = 0

        # Draw the computed eye aspect ratio on the frame to help debug
        cv2.putText(frame, "EAR: {:.2f}".format(ear), (300, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # Calculate gaze direction (this is a simplified version)
        nose_bridge = face_landmarks['nose_bridge']
        nose_point = nose_bridge[len(nose_bridge) // 2]
        left_eye_corner = leftEye[0]
        right_eye_corner = rightEye[3]
        gaze_ratio = (nose_point[0] - left_eye_corner[0]) / (right_eye_corner[0] - left_eye_corner[0])

        if gaze_ratio < 0.4 or gaze_ratio > 0.6:
            send_message("Look front!")

    # Display the frame
    cv2.imshow('Frame', frame)

    # Exit on pressing 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close windows
cap.release()
cv2.destroyAllWindows()
